{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(datasets, experiment_name, metrics_list):\n",
    "    \"\"\"Given a list of datasets, compute the average metrics for each dataset.\"\"\"\n",
    "    metrics = [[] for _ in metrics_list]\n",
    "    for dataset in datasets:\n",
    "        filename = f\"../renders-postprocessed/{dataset}/{dataset}---{experiment_name}/{dataset}---{experiment_name}.json\"\n",
    "        with open(filename, \"r\") as f:\n",
    "            metrics_dict = json.load(f)\n",
    "            for idx, metric_name in enumerate(metrics_list):\n",
    "                metrics[idx].append(metrics_dict[metric_name])\n",
    "    # get the mean\n",
    "    metrics = [sum(metric) / len(metric) for metric in metrics]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \\\n",
    "\"\"\"\n",
    "\\\\begin{table*}[]\n",
    "    \\\\centering\n",
    "    \\\\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
    "        \\\\toprule\n",
    "        COLUMNS \\\\\\\\\n",
    "        \\\\midrule\n",
    "        EXPERIMENT_LINES\n",
    "        \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "    \\\\caption{\\\\textbf{CAPTION_TITLE.} CAPTION_TEXT}\n",
    "    \\\\label{tab:TABLE_LABEL}\n",
    "\\\\end{table*}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 24.81 & 0.8086 & 0.1485 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.89 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 17.23 & 0.5308 & 0.3736 & 232.36 & 0.53 & 60.70 & 54.79 & 0.26 & 0.87 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 17.92 & 0.6071 & 0.2516 & 142.99 & 0.09 & 56.33 & 49.86 & 0.29 & 0.61 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``Average\" capture quantitative evaluation.} caption text}\n",
      "    \\label{tab:average}\n",
      "\\end{table*}\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 23.32 & 0.8343 & 0.0995 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.84 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 18.37 & 0.6248 & 0.2786 & 0.01 & 0.02 & 41.28 & 34.27 & 0.43 & 0.84 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 18.88 & 0.6582 & 0.2198 & 0.01 & 0.02 & 40.05 & 33.58 & 0.44 & 0.79 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``aloe\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:aloe}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 24.53 & 0.8263 & 0.0993 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.88 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 14.09 & 0.3645 & 0.4019 & 2568.12 & 0.20 & 62.44 & 56.38 & 0.23 & 0.87 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 14.16 & 0.4073 & 0.3609 & 1402.19 & 0.16 & 59.91 & 54.08 & 0.23 & 0.70 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``art\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:art}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 22.60 & 0.7081 & 0.2600 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.80 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 15.85 & 0.4278 & 0.4548 & 43.05 & 0.45 & 68.30 & 63.71 & 0.19 & 0.80 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 17.51 & 0.5616 & 0.2636 & 8.34 & 0.15 & 62.99 & 56.74 & 0.23 & 0.55 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``car\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:car}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 23.75 & 0.8444 & 0.1074 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.95 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 13.67 & 0.3994 & 0.4810 & 1.75 & 1.55 & 63.08 & 56.71 & 0.25 & 0.97 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 15.28 & 0.5106 & 0.2704 & 0.16 & 0.12 & 56.23 & 49.38 & 0.28 & 0.74 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``century\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:century}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 26.82 & 0.8652 & 0.1124 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.97 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 15.37 & 0.4562 & 0.4349 & 19.18 & 0.14 & 67.21 & 61.98 & 0.19 & 0.91 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 16.06 & 0.5123 & 0.3130 & 0.50 & 0.08 & 60.85 & 54.18 & 0.25 & 0.66 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``flowers\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:flowers}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 24.26 & 0.7892 & 0.1848 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 1.00 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 14.81 & 0.3984 & 0.5238 & 0.09 & 2.32 & 64.09 & 59.09 & 0.24 & 1.00 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 15.88 & 0.4786 & 0.3597 & 0.00 & 0.10 & 53.21 & 45.80 & 0.32 & 0.63 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``garbage\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:garbage}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 22.87 & 0.6938 & 0.2469 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.95 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 15.92 & 0.3238 & 0.5353 & 0.10 & 0.60 & 57.32 & 50.83 & 0.27 & 0.96 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 15.87 & 0.4672 & 0.3168 & 0.08 & 0.10 & 53.89 & 46.42 & 0.31 & 0.54 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``picnic\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:picnic}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 19.60 & 0.6047 & 0.3121 & 0.00 & 0.00 & 0.02 & 0.02 & 1.00 & 0.80 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 22.67 & 0.7251 & 0.2723 & 34.02 & 0.50 & 85.63 & 83.37 & 0.04 & 0.88 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 24.83 & 0.9046 & 0.0551 & 13.30 & 0.04 & 83.38 & 81.94 & 0.04 & 0.23 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``pikachu\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:pikachu}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 23.34 & 0.7814 & 0.1612 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.94 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 19.47 & 0.5729 & 0.2898 & 0.04 & 0.07 & 59.50 & 53.39 & 0.25 & 0.91 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 19.29 & 0.5966 & 0.2656 & 0.04 & 0.07 & 59.17 & 53.10 & 0.25 & 0.80 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``pipe\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:pipe}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 29.85 & 0.9304 & 0.0570 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.60 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 18.65 & 0.6635 & 0.2529 & 121.72 & 0.12 & 65.79 & 59.86 & 0.23 & 0.55 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 19.42 & 0.7476 & 0.1273 & 291.15 & 0.04 & 56.52 & 48.08 & 0.31 & 0.19 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``plant\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:plant}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 29.49 & 0.9152 & 0.0548 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.91 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 20.14 & 0.7196 & 0.2410 & 0.14 & 0.02 & 45.47 & 38.39 & 0.38 & 0.92 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 19.47 & 0.7181 & 0.2158 & 0.03 & 0.02 & 46.48 & 39.82 & 0.36 & 0.88 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``roses\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:roses}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 27.26 & 0.9097 & 0.0862 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.99 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 17.80 & 0.6942 & 0.3165 & 0.04 & 0.34 & 48.35 & 39.53 & 0.38 & 0.83 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 18.41 & 0.7221 & 0.2514 & 0.02 & 0.12 & 43.23 & 35.20 & 0.42 & 0.63 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``table\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:table}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COLUMNS = \"\\n & PSNR $\\\\uparrow$ & SSIM $\\\\uparrow$ & LPIPS $\\\\downarrow$ & Depth $\\\\downarrow$ & Disp. $\\\\downarrow$ & Mean $^{\\\\circ}$ $\\\\downarrow$ & Median $^{\\\\circ}$ $\\\\downarrow$ & \\\\% $30^{\\\\circ}$ $\\\\uparrow$ & Coverage $\\\\uparrow$\"\n",
    "METRICS_LIST = [\"psnr\", \"ssim\", \"lpips\", \"depth\", \"disparity\", \"normals\", \"normals_median\", \"normals_30\", \"coverage\"]\n",
    "SIGFIGS = [2, 4, 4, 2, 2, 2, 2, 2, 2]\n",
    "assert len(METRICS_LIST) == len(SIGFIGS)\n",
    "# methods are the columns\n",
    "# here we map the title in the column to the the method name (which we can grab from folder names)\n",
    "METHODS = [\n",
    "    (\"Nerfacto Pseudo GT   \", \"nerfacto---pseudo-gt\"),\n",
    "    (\"Nerfacto             \", \"nerfacto\"),\n",
    "  #  (\" + Visibility Loss   \", \"nerfacto-visibility\"),\n",
    "  #  (\" + Vis + Sparsity    \", \"nerfacto-visibility-sparsity\"),\n",
    "  #  (\" + Vis + TV          \", \"nerfacto-visibility-TV\"),\n",
    "  #  (\" + Vis + RegNeRF     \", \"nerfacto-visibility-regnerf\"),\n",
    "    (\" + Vis + DSDS (Ours) \", \"nerfacto-visibility-cube\"),\n",
    "]\n",
    "# uncomment this for ablations\n",
    "# METHODS = [\n",
    "#     (\"Nerfacto GT\", \"nerfacto---pseudo-gt\"),\n",
    "#     (\"Nerfacto          \", \"nerfacto\"),\n",
    "#     (\" + Visibility Loss\", \"nerfacto-visibility\"),\n",
    "#     (\" + Vis + RegNeRF  \", \"nerfacto-visibility-regnerf\"),\n",
    "#     (\" + Vis + Sparsity \", \"nerfacto-visibility-sparsity\"),\n",
    "#     (\" + Vis + TV       \", \"nerfacto-visibility-TV\"),\n",
    "#     (\" + Vis + Cube     \", \"nerfacto-visibility-cube\"),\n",
    "#     # sampling\n",
    "#     (\" + Vis + Cube (sampling-densities)    \", \"nerfacto-frustum-cube-sampling-densities\"),\n",
    "#     (\" + Vis + Cube (sampling-uniform)     \", \"nerfacto-frustum-cube-sampling-uniform\"),\n",
    "#     # activation\n",
    "#     (\" + Vis + Cube (activation-sigmoid)     \", \"nerfacto-frustum-cube-activation-sigmoid\"),\n",
    "#     (\" + Vis + Cube (activation-clamp)     \", \"nerfacto-frustum-cube-activation-clamp\"),\n",
    "#     # cubesize\n",
    "#     (\" + Vis + Cube (cubescale-10-20)     \", \"nerfacto-frustum-cube-cubescale-10-20\"),\n",
    "#     (\" + Vis + Cube (cubescale-01-20)    \", \"nerfacto-frustum-cube-cubescale-01-20\"),\n",
    "# ]\n",
    "DATASETS = [\n",
    "    \"aloe\",\n",
    "    \"art\",\n",
    "    \"car\",\n",
    "    \"century\",\n",
    "    \"flowers\",\n",
    "    \"garbage\",\n",
    "    \"picnic\",\n",
    "    \"pikachu\",\n",
    "    \"pipe\",\n",
    "    \"plant\",\n",
    "    \"roses\",\n",
    "    \"table\",\n",
    "]\n",
    "# DATASETS = ['aloe']\n",
    "# uncomment this for ablations\n",
    "#DATASETS = ['garbage']\n",
    "\n",
    "def print_datasets(datasets, caption_title=\"caption title\", TABLE_LABEL=\"label\", caption_text=\"caption text\"):\n",
    "    #metrics = get_metrics(datasets, \"nerfacto-visibility-sparsity\", METRICS_LIST)\n",
    "    #metrics = [str(f\"{metric:.{sigfigs}f}\") for metric, sigfigs in zip(metrics, SIGFIGS)]\n",
    "\n",
    "    # create the experiment lines\n",
    "    EXPERIMENT_LINES = [\"\\n\"]\n",
    "    for idx, (method_name, experiment_name) in enumerate(METHODS):\n",
    "        if idx == 1:\n",
    "            line_string = f\"\\\\midrule \\n\"\n",
    "            EXPERIMENT_LINES.append(line_string)\n",
    "        metrics = get_metrics(datasets, experiment_name, METRICS_LIST)\n",
    "        metrics = [str(f\"{metric:.{sigfigs}f}\") for metric, sigfigs in zip(metrics, SIGFIGS)]\n",
    "        line_string = f\"{method_name} & {' & '.join(metrics)} \\\\\\\\ \\n\"\n",
    "        EXPERIMENT_LINES.append(line_string)\n",
    "\n",
    "    s = TEMPLATE.replace(\"COLUMNS\", COLUMNS)\n",
    "    s = s.replace(\"EXPERIMENT_LINES\", \" \".join(EXPERIMENT_LINES))\n",
    "    s = s.replace(\"CAPTION_TITLE\", caption_title)\n",
    "    s = s.replace(\"CAPTION_TEXT\", caption_text)\n",
    "    s = s.replace(\"TABLE_LABEL\", TABLE_LABEL)\n",
    "    print(s)\n",
    "\n",
    "# for the average of all the datasets\n",
    "print_datasets(DATASETS, caption_title=\"``Average\\\" capture quantitative evaluation\", TABLE_LABEL=\"average\")\n",
    "\n",
    "print(\"---\" * 10)\n",
    "\n",
    "# for all the datasets individually\n",
    "for i in range(len(DATASETS)):\n",
    "    caption_title = f\"\"\"``{DATASETS[i]}\\\"\"\"\" + \" capture quantitative evaluation\"\n",
    "    caption_text = \"\"\"Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). \"\"\" + \\\n",
    "        \"\"\"We highlight that all baselines use the proposed visibility loss. \\\\cref{sec:evaluation_procedure} describes metrics in more detail, $\\\\uparrow$/$\\\\downarrow$ indicates if higher/lower is better.\"\"\"\n",
    "    print_datasets(DATASETS[i : i + 1], caption_title=caption_title, TABLE_LABEL=DATASETS[i], caption_text=caption_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
