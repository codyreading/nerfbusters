{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(datasets, experiment_name, metrics_list):\n",
    "    \"\"\"Given a list of datasets, compute the average metrics for each dataset.\"\"\"\n",
    "    metrics = [[] for _ in metrics_list]\n",
    "    for dataset in datasets:\n",
    "        filename = f\"../renders-postprocessed/{dataset}/{dataset}---{experiment_name}/{dataset}---{experiment_name}.json\"\n",
    "        with open(filename, \"r\") as f:\n",
    "            metrics_dict = json.load(f)\n",
    "            for idx, metric_name in enumerate(metrics_list):\n",
    "                metrics[idx].append(metrics_dict[metric_name])\n",
    "    # get the mean\n",
    "    metrics = [sum(metric) / len(metric) for metric in metrics]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \\\n",
    "\"\"\"\n",
    "\\\\begin{table*}[]\n",
    "    \\\\centering\n",
    "    \\\\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
    "        \\\\toprule\n",
    "        COLUMNS \\\\\\\\\n",
    "        \\\\midrule\n",
    "        EXPERIMENT_LINES\n",
    "        \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "    \\\\caption{\\\\textbf{CAPTION_TITLE.} CAPTION_TEXT}\n",
    "    \\\\label{tab:TABLE_LABEL}\n",
    "\\\\end{table*}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 24.78 & 0.8084 & 0.1489 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.89 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 17.25 & 0.5318 & 0.3725 & 195.82 & 0.52 & 60.74 & 54.82 & 0.26 & 0.87 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 17.99 & 0.6073 & 0.2519 & 104.45 & 0.10 & 56.29 & 49.92 & 0.29 & 0.61 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``Average\" capture quantitative evaluation.} caption text}\n",
      "    \\label{tab:average}\n",
      "\\end{table*}\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 23.32 & 0.8343 & 0.0995 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.84 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 18.44 & 0.6262 & 0.2768 & 0.01 & 0.02 & 41.24 & 34.25 & 0.44 & 0.84 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 18.86 & 0.6584 & 0.2167 & 0.01 & 0.02 & 39.82 & 33.14 & 0.45 & 0.79 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``aloe\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:aloe}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 24.48 & 0.8253 & 0.1001 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.88 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 14.12 & 0.3650 & 0.4022 & 2242.89 & 0.20 & 62.52 & 56.47 & 0.23 & 0.86 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 14.24 & 0.4086 & 0.3602 & 1228.78 & 0.16 & 60.52 & 54.72 & 0.23 & 0.71 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``art\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:art}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 22.58 & 0.7076 & 0.2613 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.80 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 15.80 & 0.4263 & 0.4553 & 51.05 & 0.37 & 68.48 & 63.93 & 0.19 & 0.80 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 17.58 & 0.5681 & 0.2596 & 11.95 & 0.29 & 63.66 & 57.48 & 0.23 & 0.56 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``car\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:car}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 23.70 & 0.8446 & 0.1074 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.95 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 13.49 & 0.3977 & 0.4837 & 1.83 & 1.52 & 63.24 & 56.97 & 0.24 & 0.97 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 15.52 & 0.5172 & 0.2647 & 0.25 & 0.12 & 56.10 & 49.34 & 0.28 & 0.73 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``century\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:century}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 26.73 & 0.8646 & 0.1136 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.97 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 15.33 & 0.4557 & 0.4366 & 14.78 & 0.15 & 67.08 & 61.82 & 0.19 & 0.91 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 16.03 & 0.5090 & 0.3158 & 1.80 & 0.07 & 60.37 & 53.63 & 0.25 & 0.67 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``flowers\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:flowers}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 24.22 & 0.7889 & 0.1842 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 1.00 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 14.75 & 0.4033 & 0.5210 & 0.10 & 2.48 & 64.08 & 59.05 & 0.24 & 1.00 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 16.03 & 0.4685 & 0.3753 & 0.00 & 0.10 & 54.56 & 47.27 & 0.31 & 0.62 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``garbage\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:garbage}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 22.89 & 0.6944 & 0.2484 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.95 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 15.92 & 0.3242 & 0.5343 & 0.10 & 0.53 & 57.61 & 51.14 & 0.27 & 0.96 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 15.65 & 0.4447 & 0.3384 & 0.09 & 0.17 & 55.20 & 47.85 & 0.30 & 0.60 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``picnic\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:picnic}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 19.60 & 0.6047 & 0.3121 & 0.00 & 0.00 & 0.02 & 0.02 & 1.00 & 0.80 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 22.79 & 0.7312 & 0.2659 & 34.22 & 0.48 & 85.55 & 83.38 & 0.04 & 0.89 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 24.73 & 0.9077 & 0.0556 & 7.76 & 0.03 & 82.14 & 81.14 & 0.04 & 0.17 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``pikachu\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:pikachu}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 23.32 & 0.7812 & 0.1613 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.94 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 19.48 & 0.5731 & 0.2903 & 0.04 & 0.07 & 59.74 & 53.69 & 0.25 & 0.91 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 19.44 & 0.6087 & 0.2612 & 0.03 & 0.07 & 58.90 & 52.83 & 0.25 & 0.79 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``pipe\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:pipe}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 29.87 & 0.9305 & 0.0569 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.60 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 18.89 & 0.6668 & 0.2462 & 4.74 & 0.11 & 65.46 & 59.38 & 0.23 & 0.54 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 19.78 & 0.7469 & 0.1309 & 2.67 & 0.03 & 53.67 & 45.00 & 0.33 & 0.21 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``plant\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:plant}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 29.47 & 0.9152 & 0.0547 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.91 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 20.16 & 0.7191 & 0.2425 & 0.06 & 0.02 & 45.55 & 38.41 & 0.38 & 0.92 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 19.53 & 0.7224 & 0.2059 & 0.03 & 0.02 & 49.35 & 42.60 & 0.33 & 0.87 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``roses\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:roses}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[]\n",
      "    \\centering\n",
      "    \\begin{tabular}{l|lll|ll|lllll|l} % the number of columns needed\n",
      "        \\toprule\n",
      "        \n",
      " & PSNR $\\uparrow$ & SSIM $\\uparrow$ & LPIPS $\\downarrow$ & Depth $\\downarrow$ & Disp. $\\downarrow$ & Mean $^{\\circ}$ $\\downarrow$ & Median $^{\\circ}$ $\\downarrow$ & \\% $30^{\\circ}$ $\\uparrow$ & Coverage $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \n",
      " Nerfacto Pseudo GT    & 27.22 & 0.9096 & 0.0873 & 0.00 & 0.00 & 0.01 & 0.00 & 1.00 & 0.99 \\\\ \n",
      " \\midrule \n",
      " Nerfacto              & 17.84 & 0.6934 & 0.3150 & 0.04 & 0.34 & 48.33 & 39.36 & 0.39 & 0.83 \\\\ \n",
      "  + Vis + DSDS (Ours)  & 18.49 & 0.7275 & 0.2390 & 0.02 & 0.11 & 41.15 & 33.98 & 0.44 & 0.64 \\\\ \n",
      "\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{\\textbf{``table\" capture quantitative evaluation.} Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). We highlight that all baselines use the proposed visibility loss. \\cref{sec:evaluation_procedure} describes metrics in more detail, $\\uparrow$/$\\downarrow$ indicates if higher/lower is better.}\n",
      "    \\label{tab:table}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COLUMNS = \"\\n & PSNR $\\\\uparrow$ & SSIM $\\\\uparrow$ & LPIPS $\\\\downarrow$ & Depth $\\\\downarrow$ & Disp. $\\\\downarrow$ & Mean $^{\\\\circ}$ $\\\\downarrow$ & Median $^{\\\\circ}$ $\\\\downarrow$ & \\\\% $30^{\\\\circ}$ $\\\\uparrow$ & Coverage $\\\\uparrow$\"\n",
    "METRICS_LIST = [\"psnr\", \"ssim\", \"lpips\", \"depth\", \"disparity\", \"normals\", \"normals_median\", \"normals_30\", \"coverage\"]\n",
    "SIGFIGS = [2, 4, 4, 2, 2, 2, 2, 2, 2]\n",
    "assert len(METRICS_LIST) == len(SIGFIGS)\n",
    "# methods are the columns\n",
    "# here we map the title in the column to the the method name (which we can grab from folder names)\n",
    "METHODS = [\n",
    "    (\"Nerfacto Pseudo GT   \", \"nerfacto---pseudo-gt\"),\n",
    "    (\"Nerfacto             \", \"nerfacto\"),\n",
    "  #  (\" + Visibility Loss   \", \"nerfacto-visibility\"),\n",
    "  #  (\" + Vis + Sparsity    \", \"nerfacto-visibility-sparsity\"),\n",
    "  #  (\" + Vis + TV          \", \"nerfacto-visibility-TV\"),\n",
    "  #  (\" + Vis + RegNeRF     \", \"nerfacto-visibility-regnerf\"),\n",
    "    (\" + Vis + DSDS (Ours) \", \"nerfacto-visibility-cube\"),\n",
    "]\n",
    "# uncomment this for ablations\n",
    "# METHODS = [\n",
    "#     (\"Nerfacto GT\", \"nerfacto---pseudo-gt\"),\n",
    "#     (\"Nerfacto          \", \"nerfacto\"),\n",
    "#     (\" + Visibility Loss\", \"nerfacto-visibility\"),\n",
    "#     (\" + Vis + RegNeRF  \", \"nerfacto-visibility-regnerf\"),\n",
    "#     (\" + Vis + Sparsity \", \"nerfacto-visibility-sparsity\"),\n",
    "#     (\" + Vis + TV       \", \"nerfacto-visibility-TV\"),\n",
    "#     (\" + Vis + Cube     \", \"nerfacto-visibility-cube\"),\n",
    "#     # sampling\n",
    "#     (\" + Vis + Cube (sampling-densities)    \", \"nerfacto-frustum-cube-sampling-densities\"),\n",
    "#     (\" + Vis + Cube (sampling-uniform)     \", \"nerfacto-frustum-cube-sampling-uniform\"),\n",
    "#     # activation\n",
    "#     (\" + Vis + Cube (activation-sigmoid)     \", \"nerfacto-frustum-cube-activation-sigmoid\"),\n",
    "#     (\" + Vis + Cube (activation-clamp)     \", \"nerfacto-frustum-cube-activation-clamp\"),\n",
    "#     # cubesize\n",
    "#     (\" + Vis + Cube (cubescale-10-20)     \", \"nerfacto-frustum-cube-cubescale-10-20\"),\n",
    "#     (\" + Vis + Cube (cubescale-01-20)    \", \"nerfacto-frustum-cube-cubescale-01-20\"),\n",
    "# ]\n",
    "DATASETS = [\n",
    "    \"aloe\",\n",
    "    \"art\",\n",
    "    \"car\",\n",
    "    \"century\",\n",
    "    \"flowers\",\n",
    "    \"garbage\",\n",
    "    \"picnic\",\n",
    "    \"pikachu\",\n",
    "    \"pipe\",\n",
    "    \"plant\",\n",
    "    \"roses\",\n",
    "    \"table\",\n",
    "]\n",
    "# DATASETS = ['aloe']\n",
    "# uncomment this for ablations\n",
    "#DATASETS = ['garbage']\n",
    "\n",
    "def print_datasets(datasets, caption_title=\"caption title\", TABLE_LABEL=\"label\", caption_text=\"caption text\"):\n",
    "    #metrics = get_metrics(datasets, \"nerfacto-visibility-sparsity\", METRICS_LIST)\n",
    "    #metrics = [str(f\"{metric:.{sigfigs}f}\") for metric, sigfigs in zip(metrics, SIGFIGS)]\n",
    "\n",
    "    # create the experiment lines\n",
    "    EXPERIMENT_LINES = [\"\\n\"]\n",
    "    for idx, (method_name, experiment_name) in enumerate(METHODS):\n",
    "        if idx == 1:\n",
    "            line_string = f\"\\\\midrule \\n\"\n",
    "            EXPERIMENT_LINES.append(line_string)\n",
    "        metrics = get_metrics(datasets, experiment_name, METRICS_LIST)\n",
    "        metrics = [str(f\"{metric:.{sigfigs}f}\") for metric, sigfigs in zip(metrics, SIGFIGS)]\n",
    "        line_string = f\"{method_name} & {' & '.join(metrics)} \\\\\\\\ \\n\"\n",
    "        EXPERIMENT_LINES.append(line_string)\n",
    "\n",
    "    s = TEMPLATE.replace(\"COLUMNS\", COLUMNS)\n",
    "    s = s.replace(\"EXPERIMENT_LINES\", \" \".join(EXPERIMENT_LINES))\n",
    "    s = s.replace(\"CAPTION_TITLE\", caption_title)\n",
    "    s = s.replace(\"CAPTION_TEXT\", caption_text)\n",
    "    s = s.replace(\"TABLE_LABEL\", TABLE_LABEL)\n",
    "    print(s)\n",
    "\n",
    "# for the average of all the datasets\n",
    "print_datasets(DATASETS, caption_title=\"``Average\\\" capture quantitative evaluation\", TABLE_LABEL=\"average\")\n",
    "\n",
    "print(\"---\" * 10)\n",
    "\n",
    "# for all the datasets individually\n",
    "for i in range(len(DATASETS)):\n",
    "    caption_title = f\"\"\"``{DATASETS[i]}\\\"\"\"\" + \" capture quantitative evaluation\"\n",
    "    caption_text = \"\"\"Per scene results that compare Nerfacto with baselines (that uses geometric handcrafted regularizers) and Nerfbusters (that uses a data-driven local 3D prior). \"\"\" + \\\n",
    "        \"\"\"We highlight that all baselines use the proposed visibility loss. \\\\cref{sec:evaluation_procedure} describes metrics in more detail, $\\\\uparrow$/$\\\\downarrow$ indicates if higher/lower is better.\"\"\"\n",
    "    print_datasets(DATASETS[i : i + 1], caption_title=caption_title, TABLE_LABEL=DATASETS[i], caption_text=caption_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
